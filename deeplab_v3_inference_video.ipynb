{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fa2c8e5-697c-492e-a950-d1d961ce4ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2829379-f6f1-4316-af07-e4fa73fe5b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the device is correctly set\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the trained model with ignoring unexpected keys\n",
    "model = models.segmentation.deeplabv3_resnet50(weights=None, num_classes=2)\n",
    "checkpoint = torch.load('deeplabv3_rock_detection.pth')\n",
    "model.load_state_dict(checkpoint, strict=False)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d51d6b2-22c1-447a-b66d-8f77aab75070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process a single frame\n",
    "def process_frame(frame, model, transform, device):\n",
    "    # Convert frame to PIL Image\n",
    "    image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    input_image = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        output = model(input_image)['out']\n",
    "    prediction = torch.argmax(output.squeeze(), dim=0).cpu().numpy()\n",
    "    \n",
    "    # Resize prediction to match original frame size\n",
    "    prediction_resized = np.array(Image.fromarray(prediction.astype(np.uint8)).resize((frame.shape[1], frame.shape[0]), resample=Image.NEAREST))\n",
    "    \n",
    "    # Overlay the mask on the original frame\n",
    "    mask_overlay = Image.fromarray(prediction_resized).convert(\"RGBA\")\n",
    "    mask_overlay = Image.blend(image.convert(\"RGBA\"), mask_overlay, alpha=0.5)\n",
    "    \n",
    "    # Convert back to OpenCV format\n",
    "    overlay_frame = cv2.cvtColor(np.array(mask_overlay), cv2.COLOR_RGBA2BGR)\n",
    "    \n",
    "    return overlay_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db7aad1b-ca7d-40c7-9125-54853ff4ee5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process a video\n",
    "def process_video(input_video_path, output_video_path, model, transform, device):\n",
    "    # Open the input video\n",
    "    cap = cv2.VideoCapture(input_video_path)\n",
    "    \n",
    "    # Get video properties\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    # Initialize tqdm progress bar\n",
    "    with tqdm(total=total_frames, desc=\"Processing Video\") as pbar:\n",
    "        for _ in range(total_frames):\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            # Process the frame\n",
    "            overlay_frame = process_frame(frame, model, transform, device)\n",
    "            \n",
    "            # Write the frame to the output video\n",
    "            out.write(overlay_frame)\n",
    "            \n",
    "            # Update progress bar\n",
    "            pbar.update(1)\n",
    "    \n",
    "    # Release everything if job is finished\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c35098d8-d5a9-4e85-a252-d0ad9e01df22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the input video\n",
    "input_video_path = 'sample_video.mp4'\n",
    "\n",
    "# Path to the output video\n",
    "output_video_path = 'deeplab_v3_output_video.avi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56d1e5fa-e1d8-4789-a6fb-b1819141239b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Video: 100%|███████████████████████| 901/901 [00:37<00:00, 24.29it/s]\n"
     ]
    }
   ],
   "source": [
    "# Process the video # EXECUTE THE INFERENCE\n",
    "process_video(input_video_path, output_video_path, model, transform, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07c5e1b-47a8-4b0f-8971-89a2bbeaadb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
